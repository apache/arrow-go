// Licensed to the Apache Software Foundation (ASF) under one
// or more contributor license agreements.  See the NOTICE file
// distributed with this work for additional information
// regarding copyright ownership.  The ASF licenses this file
// to you under the Apache License, Version 2.0 (the
// "License"); you may not use this file except in compliance
// with the License.  You may obtain a copy of the License at
//
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Code generated by the FlatBuffers compiler. DO NOT EDIT.

package flatbuf

import (
	flatbuffers "github.com/google/flatbuffers/go"
)

// / ----------------------------------------------------------------------
// / EXPERIMENTAL: Data structures for sparse tensors
// / Coordinate (COO) format of sparse tensor index.
// /
// / COO's index list are represented as a NxM matrix,
// / where N is the number of non-zero values,
// / and M is the number of dimensions of a sparse tensor.
// /
// / indicesBuffer stores the location and size of the data of this indices
// / matrix.  The value type and the stride of the indices matrix is
// / specified in indicesType and indicesStrides fields.
// /
// / For example, let X be a 2x3x4x5 tensor, and it has the following
// / 6 non-zero values:
// / ```text
// /   X[0, 1, 2, 0] := 1
// /   X[1, 1, 2, 3] := 2
// /   X[0, 2, 1, 0] := 3
// /   X[0, 1, 3, 0] := 4
// /   X[0, 1, 2, 1] := 5
// /   X[1, 2, 0, 4] := 6
// / ```
// / In COO format, the index matrix of X is the following 4x6 matrix:
// / ```text
// /   [[0, 0, 0, 0, 1, 1],
// /    [1, 1, 1, 2, 1, 2],
// /    [2, 2, 3, 1, 2, 0],
// /    [0, 1, 0, 0, 3, 4]]
// / ```
// / When isCanonical is true, the indices is sorted in lexicographical order
// / (row-major order), and it does not have duplicated entries.  Otherwise,
// / the indices may not be sorted, or may have duplicated entries.
type SparseTensorIndexCOO struct {
	flatbuffers.Table
}

func GetRootAsSparseTensorIndexCOO(buf []byte, offset flatbuffers.UOffsetT) (x SparseTensorIndexCOO) {
	n := flatbuffers.GetUOffsetT(buf[offset:])
	x.Table = flatbuffers.Table{Bytes: buf, Pos: n+offset}
	return
}

func (rcv *SparseTensorIndexCOO) Init(buf []byte, i flatbuffers.UOffsetT) {
	rcv.Bytes = buf
	rcv.Pos = i
}

// / The type of values in indicesBuffer
func (rcv *SparseTensorIndexCOO) IndicesType(obj *Int) *Int {
	o := flatbuffers.UOffsetT(rcv.Offset(4))
	if o != 0 {
		x := rcv.Indirect(o + rcv.Pos)
		if obj == nil {
			obj = new(Int)
		}
		obj.Init(rcv.Bytes, x)
		return obj
	}
	return nil
}

// / The type of values in indicesBuffer
// / Non-negative byte offsets to advance one value cell along each dimension
// / If omitted, default to row-major order (C-like).
func (rcv *SparseTensorIndexCOO) IndicesStrides(j int) int64 {
	o := flatbuffers.UOffsetT(rcv.Offset(6))
	if o != 0 {
		a := rcv.Vector(o)
		return rcv.GetInt64(a + flatbuffers.UOffsetT(j*8))
	}
	return 0
}

func (rcv *SparseTensorIndexCOO) IndicesStridesLength() int {
	o := flatbuffers.UOffsetT(rcv.Offset(6))
	if o != 0 {
		return rcv.VectorLen(o)
	}
	return 0
}

// / Non-negative byte offsets to advance one value cell along each dimension
// / If omitted, default to row-major order (C-like).
func (rcv *SparseTensorIndexCOO) MutateIndicesStrides(j int, n int64) bool {
	o := flatbuffers.UOffsetT(rcv.Offset(6))
	if o != 0 {
		a := rcv.Vector(o)
		return rcv.MutateInt64(a+flatbuffers.UOffsetT(j*8), n)
	}
	return false
}

// / The location and size of the indices matrix's data
func (rcv *SparseTensorIndexCOO) IndicesBuffer(obj *Buffer) *Buffer {
	o := flatbuffers.UOffsetT(rcv.Offset(8))
	if o != 0 {
		x := o + rcv.Pos
		if obj == nil {
			obj = new(Buffer)
		}
		obj.Init(rcv.Bytes, x)
		return obj
	}
	return nil
}

// / The location and size of the indices matrix's data
// / This flag is true if and only if the indices matrix is sorted in
// / row-major order, and does not have duplicated entries.
// / This sort order is the same as of Tensorflow's SparseTensor,
// / but it is inverse order of SciPy's canonical coo_matrix
// / (SciPy employs column-major order for its coo_matrix).
func (rcv *SparseTensorIndexCOO) IsCanonical() bool {
	o := flatbuffers.UOffsetT(rcv.Offset(10))
	if o != 0 {
		return rcv.GetBool(o + rcv.Pos)
	}
	return false
}

// / This flag is true if and only if the indices matrix is sorted in
// / row-major order, and does not have duplicated entries.
// / This sort order is the same as of Tensorflow's SparseTensor,
// / but it is inverse order of SciPy's canonical coo_matrix
// / (SciPy employs column-major order for its coo_matrix).
func (rcv *SparseTensorIndexCOO) MutateIsCanonical(n bool) bool {
	return rcv.MutateBoolSlot(10, n)
}

func SparseTensorIndexCOOStart(builder *flatbuffers.Builder) {
	builder.StartObject(4)
}
func SparseTensorIndexCOOAddIndicesType(builder *flatbuffers.Builder, indicesType flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(0, flatbuffers.UOffsetT(indicesType), 0)
}
func SparseTensorIndexCOOAddIndicesStrides(builder *flatbuffers.Builder, indicesStrides flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(1, flatbuffers.UOffsetT(indicesStrides), 0)
}
func SparseTensorIndexCOOStartIndicesStridesVector(builder *flatbuffers.Builder, numElems int) flatbuffers.UOffsetT {
	return builder.StartVector(8, numElems, 8)
}
func SparseTensorIndexCOOAddIndicesBuffer(builder *flatbuffers.Builder, indicesBuffer flatbuffers.UOffsetT) {
	builder.PrependStructSlot(2, flatbuffers.UOffsetT(indicesBuffer), 0)
}
func SparseTensorIndexCOOAddIsCanonical(builder *flatbuffers.Builder, isCanonical bool) {
	builder.PrependBoolSlot(3, isCanonical, false)
}
func SparseTensorIndexCOOEnd(builder *flatbuffers.Builder) flatbuffers.UOffsetT {
	return builder.EndObject()
}
